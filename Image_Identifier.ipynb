{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Index\n","\n","[1. Import Libraries](#1.-Import-libraries)\n","\n","[2. Get Training data](#2.-Get-Training-data)\n","\n","[3. Pre-processing Data](#3.-Pre-processing-Data)\n","\n","[4. Pre-trained model for Transfer Learning](#4.-Pre-trained-model-for-Transfer-Learning)\n","\n","[5. Create custom model](#5.-Create-custom-model)\n","\n","[6. Model training](#6.-Model-training)\n","\n","[7. Test Data](#7.-Test-Data)\n","\n","[8. Class Prediction](#8.-Class-Prediction)\n","\n","[9. Model Validation](#9.-Model-Validation)\n","\n","[10. Improvisations](#10.-Improvisations)"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 1. Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:36.566187Z","iopub.status.busy":"2022-05-21T06:06:36.565922Z","iopub.status.idle":"2022-05-21T06:06:36.576995Z","shell.execute_reply":"2022-05-21T06:06:36.576118Z","shell.execute_reply.started":"2022-05-21T06:06:36.566156Z"},"trusted":true},"outputs":[],"source":["# Importing necessary libraries\n","import pandas as pd\n","import numpy as np\n","import cv2\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","%matplotlib inline\n","import seaborn as sns\n","import random\n","import os\n","import gc\n","\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras import models, Sequential\n","from tensorflow.keras import optimizers\n","\n","from keras.layers.core import Dense, Dropout, Flatten\n","from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n","\n","from tensorflow.keras.applications.vgg16 import VGG16\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import img_to_array, load_img\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import precision_recall_curve"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Get Training data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:36.605Z","iopub.status.busy":"2022-05-21T06:06:36.604678Z","iopub.status.idle":"2022-05-21T06:06:36.608502Z","shell.execute_reply":"2022-05-21T06:06:36.607735Z","shell.execute_reply.started":"2022-05-21T06:06:36.604967Z"},"trusted":true},"outputs":[],"source":["# Creating file path for our train data and test data\n","train_dir = \"AutismDataset/train\"\n","test_dir = \"AutismDataset/test\""]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n"," - Collect 'Autistic' and 'Non-Autistic' images from train data, shuffle them and use as training images\n"," - The dataset has 2450 train images, with 1225 images for each 'Autistic' and 'Non-Autistic' category\n"," - 300 test images from file path"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:36.618903Z","iopub.status.busy":"2022-05-21T06:06:36.618231Z","iopub.status.idle":"2022-05-21T06:06:36.925441Z","shell.execute_reply":"2022-05-21T06:06:36.924639Z","shell.execute_reply.started":"2022-05-21T06:06:36.618876Z"},"trusted":true},"outputs":[],"source":["# Getting 'Autistic' and 'Non-Autistic' train images from respective file names of train data\n","train_non_autistic = []\n","train_autistic = []\n","for i in os.listdir(train_dir):\n","    if 'Non_Autistic' in (\"AutismDataset/train/{}\".format(i)):\n","        train_non_autistic.append((\"AutismDataset/train/{}\".format(i)))\n","    else:\n","        train_autistic.append((\"AutismDataset/train/{}\".format(i)))\n","        \n","# Getting test images from test data file path\n","#test_imgs = [\"AutismDataset/test/{}\".format(i) for i in os.listdir(test_dir)]\n","test_imgs = [\"newTest/{}\".format(i) for i in os.listdir(test_dir)]\n","print(train_non_autistic)\n","print(test_imgs)\n","\n","\n","# Concatenate 'Autistic'  and 'Non-Autistic' images and shuffle them as train_images\n","train_imgs = train_autistic + train_non_autistic\n","random.shuffle(train_imgs)\n","\n","# Remove the lists to save space\n","del train_autistic\n","del train_non_autistic\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":["Let's see the training data samples"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:36.927361Z","iopub.status.busy":"2022-05-21T06:06:36.927049Z","iopub.status.idle":"2022-05-21T06:06:37.736961Z","shell.execute_reply":"2022-05-21T06:06:37.73621Z","shell.execute_reply.started":"2022-05-21T06:06:36.927321Z"},"trusted":true},"outputs":[],"source":["# Plot first 3 images from train_imgs\n","import matplotlib.image as mpimg\n","for ima in train_imgs[0:3]:\n","    img=mpimg.imread(ima)\n","    imgplot = plt.imshow(img)\n","    plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["* These images need to be resized and formatted before they are provided to the model"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Pre-processing Data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" - Defining the dimensions for resizing the images first\n"," - Then we write a function to read the images, resize them and specify the labels(y) for each image based on the file name - label '1' if 'Autistic' and label '0' if 'Non-Autistic'\n"," - X is the resized image and y is the class the image belongs to"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import imageio\n","def read_and_process_image(list_of_images, nrows, ncolumns):\n","    X = []\n","    y = []\n","    for image in list_of_images:\n","        try:\n","            img = imageio.imread(image)\n","            if img is None:\n","                print(\"Error: Failed to load image:\", image)\n","                continue\n","            resized_img = cv2.resize(img, (nrows, ncolumns), interpolation=cv2.INTER_CUBIC)\n","            X.append(resized_img)\n","            if 'Non_Autistic' in image:\n","                y.append(0)\n","            else:\n","                y.append(1)\n","        except Exception as e:\n","            print(\"Error processing image:\", image, e)\n","    return X, y"]},{"cell_type":"markdown","metadata":{},"source":["Call the function to read and resize train images, it returns X_train - train images and y_train - train labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:37.747936Z","iopub.status.busy":"2022-05-21T06:06:37.747284Z","iopub.status.idle":"2022-05-21T06:06:56.500333Z","shell.execute_reply":"2022-05-21T06:06:56.499481Z","shell.execute_reply.started":"2022-05-21T06:06:37.747896Z"},"trusted":true},"outputs":[],"source":["# Get resized images and labels from train data\n","X_train, y_train = read_and_process_image(train_imgs,150,150)\n","\n","# Delete train images to save space\n","del train_imgs\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Convert the resized images and labels into numpy array"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:56.50221Z","iopub.status.busy":"2022-05-21T06:06:56.501927Z","iopub.status.idle":"2022-05-21T06:06:56.828522Z","shell.execute_reply":"2022-05-21T06:06:56.826487Z","shell.execute_reply.started":"2022-05-21T06:06:56.502174Z"},"trusted":true},"outputs":[],"source":["# Convert the lists to array\n","plt.figure(figsize=(12, 8))\n","X_train = np.array(X_train)\n","y_train = np.array(y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:56.833768Z","iopub.status.busy":"2022-05-21T06:06:56.833489Z","iopub.status.idle":"2022-05-21T06:06:56.846577Z","shell.execute_reply":"2022-05-21T06:06:56.845557Z","shell.execute_reply.started":"2022-05-21T06:06:56.833732Z"},"trusted":true},"outputs":[],"source":["# Shape of train images and labels\n","print(\"Shape of train images:\", X_train.shape)\n","print(\"Shape of train labels:\", y_train.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Get and pre-process validation data\n","- 100 images in the dataset named valid, these are entirely new - 50 images in each class\n","- Using validation images to evaluate our model performance\n","- Get the validation images from the file path, shuffle them as val_imgs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:56.848657Z","iopub.status.busy":"2022-05-21T06:06:56.848345Z","iopub.status.idle":"2022-05-21T06:06:57.121158Z","shell.execute_reply":"2022-05-21T06:06:57.120452Z","shell.execute_reply.started":"2022-05-21T06:06:56.84861Z"},"trusted":true},"outputs":[],"source":["# Repeat the above process for validation data to get val_images\n","val_autistic = \"AutismDataset/valid/Autistic\"\n","val_non_autistic = \"AutismDataset/valid/Non_Autistic\"\n","val_autistic_imgs = [\"AutismDataset/valid/Autistic/{}\".format(i) for i in os.listdir(val_autistic)]\n","val_non_autistic_imgs = [\"AutismDataset/valid/Non_Autistic/{}\".format(i) for i in os.listdir(val_non_autistic)]\n","val_imgs = val_autistic_imgs + val_non_autistic_imgs\n","random.shuffle(val_imgs)\n","\n","# Remove the lists to save space\n","del val_autistic_imgs\n","del val_non_autistic_imgs\n","gc.collect()"]},{"cell_type":"markdown","metadata":{},"source":[" - Read, resize and label the validation images\n"," - X_val - validation images, y_val - validation labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:57.125348Z","iopub.status.busy":"2022-05-21T06:06:57.12483Z","iopub.status.idle":"2022-05-21T06:06:58.149939Z","shell.execute_reply":"2022-05-21T06:06:58.149263Z","shell.execute_reply.started":"2022-05-21T06:06:57.125307Z"},"trusted":true},"outputs":[],"source":["# Get resized images and labels from validation data\n","X_val, y_val = read_and_process_image(val_imgs,150,150)\n","\n","# Delete validation images to save space\n","del val_imgs\n","gc.collect()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Convert the resized images and labels into numpy array"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:58.151609Z","iopub.status.busy":"2022-05-21T06:06:58.15135Z","iopub.status.idle":"2022-05-21T06:06:58.32121Z","shell.execute_reply":"2022-05-21T06:06:58.320316Z","shell.execute_reply.started":"2022-05-21T06:06:58.151577Z"},"trusted":true},"outputs":[],"source":["# Convert the lists to array\n","plt.figure(figsize=(12, 8))\n","X_val = np.array(X_val)\n","y_val = np.array(y_val)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:58.324909Z","iopub.status.busy":"2022-05-21T06:06:58.324698Z","iopub.status.idle":"2022-05-21T06:06:58.330441Z","shell.execute_reply":"2022-05-21T06:06:58.329299Z","shell.execute_reply.started":"2022-05-21T06:06:58.324882Z"},"trusted":true},"outputs":[],"source":["# Shape of validation images and labels\n","print(\"Shape of validation images:\", X_val.shape)\n","print(\"Shape of validation labels:\", y_val.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:58.332718Z","iopub.status.busy":"2022-05-21T06:06:58.332282Z","iopub.status.idle":"2022-05-21T06:06:58.33975Z","shell.execute_reply":"2022-05-21T06:06:58.338856Z","shell.execute_reply.started":"2022-05-21T06:06:58.332567Z"},"trusted":true},"outputs":[],"source":["# Get length of train data and validation data\n","ntrain = len(X_train)\n","nval = len(X_val)\n","batch_size = 32"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Pre-trained model for Transfer Learning"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We use pre-trained Convolutional Neural Network(CNN) model VGG16 that has been trained on a large number of image data for image classification task (IMAGENET)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:06:58.341886Z","iopub.status.busy":"2022-05-21T06:06:58.341025Z","iopub.status.idle":"2022-05-21T06:07:01.625912Z","shell.execute_reply":"2022-05-21T06:07:01.624913Z","shell.execute_reply.started":"2022-05-21T06:06:58.341846Z"},"trusted":true},"outputs":[],"source":["# Calling pre-trained VGG16 model\n","base_model = VGG16(include_top=False,weights='imagenet',input_shape=(150,150,3))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:07:01.627497Z","iopub.status.busy":"2022-05-21T06:07:01.627203Z","iopub.status.idle":"2022-05-21T06:07:01.633069Z","shell.execute_reply":"2022-05-21T06:07:01.632319Z","shell.execute_reply.started":"2022-05-21T06:07:01.62746Z"},"trusted":true},"outputs":[],"source":["# Freeze the layers in pre-trained model, we don't need to train again\n","for layer in base_model.layers:\n","   layer.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:07:01.634766Z","iopub.status.busy":"2022-05-21T06:07:01.634286Z","iopub.status.idle":"2022-05-21T06:07:01.644956Z","shell.execute_reply":"2022-05-21T06:07:01.643918Z","shell.execute_reply.started":"2022-05-21T06:07:01.634724Z"},"trusted":true},"outputs":[],"source":["# Let's see how many layers are in the vgg model\n","print(\"Number of layers in the base model: \", len(base_model.layers))"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Create custom model"]},{"cell_type":"markdown","metadata":{},"source":["Connecting the pre-trained CNN model to our custom fully connnected layer"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Added a Dropout layer to stop neuron overpowering"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:07:01.646716Z","iopub.status.busy":"2022-05-21T06:07:01.646259Z","iopub.status.idle":"2022-05-21T06:07:01.731709Z","shell.execute_reply":"2022-05-21T06:07:01.730634Z","shell.execute_reply.started":"2022-05-21T06:07:01.64667Z"},"trusted":true},"outputs":[],"source":["# Create our classifier model, connect pre-trained model vgg to our model\n","model = keras.models.Sequential()\n","model.add(base_model)\n","model.add(layers.Flatten())\n","model.add(layers.Dense(512, activation = 'relu'))\n","model.add(layers.Dropout(0.3))\n","model.add(layers.Dense(1, activation = 'sigmoid'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create our classifier model, connect pre-trained model vgg to our model\n","# model = keras.models.Sequential()\n","# model.add(base_model)\n","# model.add(layers.Flatten())\n","# model.add(layers.Dense(300, activation = 'relu'))\n","# model.add(layers.Dense(300, activation = 'relu'))\n","# model.add(layers.Dropout(0.5))\n","# model.add(layers.Dense(1, activation = 'softmax'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:07:01.733739Z","iopub.status.busy":"2022-05-21T06:07:01.733434Z","iopub.status.idle":"2022-05-21T06:07:01.745998Z","shell.execute_reply":"2022-05-21T06:07:01.745186Z","shell.execute_reply.started":"2022-05-21T06:07:01.733698Z"},"trusted":true},"outputs":[],"source":["# Create summary of our model\n","model.summary()"]},{"cell_type":"markdown","metadata":{},"source":[" - Specify the loss function, optimizer and metrics for the model\n"," - 'binary-crossentropy' for loss since we are dealing with binary classification\n"," - Hyperparameter tuning is performed by choosing between optimizers and specifying learning rate to reduce loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:07:01.747942Z","iopub.status.busy":"2022-05-21T06:07:01.747666Z","iopub.status.idle":"2022-05-21T06:07:01.765223Z","shell.execute_reply":"2022-05-21T06:07:01.764213Z","shell.execute_reply.started":"2022-05-21T06:07:01.747902Z"},"trusted":true},"outputs":[],"source":["# Compile the model specifying optimizer, loss function and metrics\n","model.compile(loss = 'binary_crossentropy', optimizer = keras.optimizers.Adam(), metrics = ['acc'])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" - Image data generator performs scaling of image pixel array between 0 and 1, also image transformation like zoom, flip are performed on the available train images to increase the training data for the model, so that model won't overfit by training on small dataset\n"," - Performing scaling on validation images but don't augument images in validation dataset\n"," - Validation images are used to test the performance of our model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:07:01.767595Z","iopub.status.busy":"2022-05-21T06:07:01.767074Z","iopub.status.idle":"2022-05-21T06:07:01.7745Z","shell.execute_reply":"2022-05-21T06:07:01.773698Z","shell.execute_reply.started":"2022-05-21T06:07:01.76755Z"},"trusted":true},"outputs":[],"source":["# Configure data augumentation and scaling of images to prevent overfitting since we have a small train data\n","train_datagen = ImageDataGenerator(rescale = 1./255,\n","                                  rotation_range = 40,\n","                                  width_shift_range = 0.2,\n","                                  height_shift_range = 0.2,\n","                                  shear_range = 0.2,\n","                                  zoom_range = 0.2,\n","                                  horizontal_flip = True)\n","\n","# Only rescaling for validation data\n","val_datagen = ImageDataGenerator(rescale = 1./255)"]},{"cell_type":"markdown","metadata":{},"source":["Image generator creates batches of train and validation data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:07:01.77684Z","iopub.status.busy":"2022-05-21T06:07:01.776153Z","iopub.status.idle":"2022-05-21T06:07:01.955509Z","shell.execute_reply":"2022-05-21T06:07:01.954616Z","shell.execute_reply.started":"2022-05-21T06:07:01.7768Z"},"trusted":true},"outputs":[],"source":["# Create test and validation image generator\n","train_generator = train_datagen.flow(X_train, y_train, batch_size = batch_size)\n","val_generator = val_datagen.flow(X_val, y_val, batch_size = batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Model training"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[" - Fit and train the model on the training data and measure the performance on unseen validation data\n"," - Specify number of epochs the model has to be trained on training data\n"," - Accuracy gradually increases as epochs increase\n","    - High accuracy found at ~50 epochs (training takes a very long time)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:07:01.957321Z","iopub.status.busy":"2022-05-21T06:07:01.956865Z","iopub.status.idle":"2022-05-21T06:19:13.698752Z","shell.execute_reply":"2022-05-21T06:19:13.697595Z","shell.execute_reply.started":"2022-05-21T06:07:01.957277Z"},"trusted":true},"outputs":[],"source":["# Train the model\n","history = model.fit(train_generator,\n","                              steps_per_epoch=ntrain // batch_size,\n","                              epochs=10,\n","                              validation_data=val_generator,\n","                              validation_steps=nval // batch_size\n","                             )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:13.705748Z","iopub.status.busy":"2022-05-21T06:19:13.705537Z","iopub.status.idle":"2022-05-21T06:19:13.751908Z","shell.execute_reply":"2022-05-21T06:19:13.75118Z","shell.execute_reply.started":"2022-05-21T06:19:13.705723Z"},"trusted":true},"outputs":[],"source":["# Learning curves for training and validation\n","history_df = pd.DataFrame(history.history)\n","history_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:13.753554Z","iopub.status.busy":"2022-05-21T06:19:13.753286Z","iopub.status.idle":"2022-05-21T06:19:14.13485Z","shell.execute_reply":"2022-05-21T06:19:14.134179Z","shell.execute_reply.started":"2022-05-21T06:19:13.753518Z"},"trusted":true},"outputs":[],"source":["# Plot train and validation accuracy\n","plt.figure(figsize=(12, 8))\n","sns.lineplot(data=history_df.loc[:, [\"acc\", \"val_acc\"]], palette=['b', 'r'], dashes=False)\n","sns.set_style(\"whitegrid\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Training and Validation Accuracy\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:14.136842Z","iopub.status.busy":"2022-05-21T06:19:14.136363Z","iopub.status.idle":"2022-05-21T06:19:14.498489Z","shell.execute_reply":"2022-05-21T06:19:14.497834Z","shell.execute_reply.started":"2022-05-21T06:19:14.136803Z"},"trusted":true},"outputs":[],"source":["# Plot train and validation loss\n","plt.figure(figsize=(12, 8))\n","sns.lineplot(data=history_df.loc[:, [\"loss\", \"val_loss\"]], palette=['b', 'r'], dashes=False)\n","sns.set_style(\"whitegrid\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Training and Validation Loss\")"]},{"cell_type":"markdown","metadata":{},"source":["- The learning curve of training loss shows a good trend and the loss minimises as the number of epochs increase\n","- The learning curve of validation loss shows noise around the training loss and the validation loss tends to increase after 15-17 epochs\n","- The validation accuracy fluctuates a lot too\n","- This may be because the model has very small data for validation compared to training"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["## 7. Test Data"]},{"cell_type":"markdown","metadata":{},"source":["Read and resize the test images, convert them into numpy array"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:14.500098Z","iopub.status.busy":"2022-05-21T06:19:14.499707Z","iopub.status.idle":"2022-05-21T06:19:16.969781Z","shell.execute_reply":"2022-05-21T06:19:16.96891Z","shell.execute_reply.started":"2022-05-21T06:19:14.500059Z"},"trusted":true},"outputs":[],"source":["nrows = 150\n","ncolumns  = 150\n","channels = 3\n","\n","train_non_autistic = []\n","train_autistic = []\n","for i in os.listdir(train_dir):\n","    if 'Non_Autistic' in (\"AutismDataset/train/{}\".format(i)):\n","        train_non_autistic.append((\"AutismDataset/train/{}\".format(i)))\n","    else:\n","        train_autistic.append((\"AutismDataset/train/{}\".format(i)))\n","        \n","# Getting test images from test data file path\n","test_imgs = [\"AutismDataset/test/{}\".format(i) for i in os.listdir(test_dir)]\n","\n","print(train_non_autistic)\n","print(test_imgs)\n","\n","\n","# Concatenate 'Autistic'  and 'Non-Autistic' images and shuffle them as train_images\n","train_imgs = train_autistic + train_non_autistic\n","\n","\n","#from sklearn.model_selection import train_test_split\n","# Read and resize test images\n","random.shuffle(test_imgs)\n","\n","X_test, y_test = read_and_process_image(test_imgs,nrows,ncolumns)\n","print(X_test)\n","#X_test,y_test = train_test_split(test_imgs)\n","X = np.array(X_test)\n","#test_datagen = ImageDataGenerator(rescale = 1./255)\n"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["## 8. Class Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","output = np.round(model.predict(X_train[1:30]), 3)\n","print(output)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:16.974002Z","iopub.status.busy":"2022-05-21T06:19:16.973777Z","iopub.status.idle":"2022-05-21T06:19:17.457812Z","shell.execute_reply":"2022-05-21T06:19:17.457041Z","shell.execute_reply.started":"2022-05-21T06:19:16.973974Z"},"trusted":true},"outputs":[],"source":["# Predict label for test images\n","pred = model.predict(X)\n","threshold = 0.5\n","predictions = np.where(pred > threshold, 1,0)\n","print(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:17.459354Z","iopub.status.busy":"2022-05-21T06:19:17.45911Z","iopub.status.idle":"2022-05-21T06:19:17.478794Z","shell.execute_reply":"2022-05-21T06:19:17.476911Z","shell.execute_reply.started":"2022-05-21T06:19:17.459321Z"},"trusted":true},"outputs":[],"source":["#Plot test images and their corresponding predictions\n","test = pd.DataFrame(data = predictions, columns = [\"predictions\"])\n","test\n","test[\"filename\"] = [os.path.basename(i) for i in test_imgs]\n","test[\"test_labels\"] = y_test\n","test = test[[\"filename\", \"test_labels\", \"predictions\"]]\n","test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:17.667084Z","iopub.status.busy":"2022-05-21T06:19:17.666739Z","iopub.status.idle":"2022-05-21T06:19:17.674887Z","shell.execute_reply":"2022-05-21T06:19:17.674075Z","shell.execute_reply.started":"2022-05-21T06:19:17.667055Z"},"trusted":true},"outputs":[],"source":["model_accuracy = accuracy_score(y_test, predictions)\n","print(\"Model Accuracy: {:.2f}%\".format(model_accuracy * 100))"]},{"cell_type":"markdown","metadata":{},"source":["## 9. Model Validation"]},{"cell_type":"markdown","metadata":{},"source":["- We can evaluate the performance of the model on the test datset (since we konw the labels of the test data for this problem)\n","- We compare the metrics to select the best model\n","- For a well balanced dataset in both classes like in this dataset, Area Under the Curve of ROC can be used as evaluation metric to make comparison between models"]},{"cell_type":"markdown","metadata":{},"source":["- Classification report gives a summary of different metrics based on the predictive power of the model among positive and negative class\n","- If we are dealing with an unbalanced dataset (under most of real world circumstances), the accuracy alone is not a good metric for comparison\n","- Since models will be biased in predicitons for an unbalanced dataset, we rely on Precision, Recall metrics which take into account of Type 1 (False Positive FP) and Type 2 (False Negative FN) errors too"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:17.676536Z","iopub.status.busy":"2022-05-21T06:19:17.676201Z","iopub.status.idle":"2022-05-21T06:19:17.688596Z","shell.execute_reply":"2022-05-21T06:19:17.687706Z","shell.execute_reply.started":"2022-05-21T06:19:17.676499Z"},"trusted":true},"outputs":[],"source":["# Generating Classification report for model's performance in each class\n","cl_report = classification_report(y_test, predictions)\n","print(cl_report)"]},{"cell_type":"markdown","metadata":{},"source":["Confusion Matrix gives the summary of True Positive(TP), True Negative(TN), False Positive(FP) and False Negative(FN) predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:17.690265Z","iopub.status.busy":"2022-05-21T06:19:17.689937Z","iopub.status.idle":"2022-05-21T06:19:17.698893Z","shell.execute_reply":"2022-05-21T06:19:17.697889Z","shell.execute_reply.started":"2022-05-21T06:19:17.690228Z"},"trusted":true},"outputs":[],"source":["# Generating Confusion Matrix for the predictions against true labels\n","cn_matrix = confusion_matrix(y_test, predictions)\n","cn_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:17.70127Z","iopub.status.busy":"2022-05-21T06:19:17.700402Z","iopub.status.idle":"2022-05-21T06:19:17.933501Z","shell.execute_reply":"2022-05-21T06:19:17.932787Z","shell.execute_reply.started":"2022-05-21T06:19:17.701231Z"},"trusted":true},"outputs":[],"source":["# Plotting the True Positives, True Negatives, False Positives and False Negatives from model's predictions\n","f, ax = plt.subplots(figsize = (8,6))\n","ax = sns.heatmap(cn_matrix, annot=True)\n","ax.set_xlabel(\"Predicted\")\n","ax.set_ylabel(\"True\")\n","ax.set_title(\"Confusion Matrix\")"]},{"cell_type":"markdown","metadata":{},"source":["- The Receiver Operating Characteristic ROC curve shows the performance measure of the model in diagnosing both the classes\n","- Higher the Area under the Curve AUC, better the performance of the model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:17.934934Z","iopub.status.busy":"2022-05-21T06:19:17.934701Z","iopub.status.idle":"2022-05-21T06:19:17.942567Z","shell.execute_reply":"2022-05-21T06:19:17.941592Z","shell.execute_reply.started":"2022-05-21T06:19:17.934899Z"},"trusted":true},"outputs":[],"source":["# Let's plot the AUC-ROC curve to assess the performance of our model\n","fpr, tpr, _ = roc_curve(y_test, predictions)\n","roc_auc= auc(fpr, tpr)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:17.945381Z","iopub.status.busy":"2022-05-21T06:19:17.944278Z","iopub.status.idle":"2022-05-21T06:19:18.197001Z","shell.execute_reply":"2022-05-21T06:19:18.196276Z","shell.execute_reply.started":"2022-05-21T06:19:17.945337Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize = (10,8))\n","plt.plot(fpr, tpr, color = 'red', lw = 2, label = 'ROC curve (area = %0.2f)' % roc_auc)\n","plt.plot([1,0], [1,0], color = 'navy', lw = 2, linestyle = '--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title(\"Receiver Operating Characteristic curve\")\n","plt.legend(loc = 'lower right')"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["Let's see how the model has predcited on a set of sample test images!"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-21T06:19:18.199027Z","iopub.status.busy":"2022-05-21T06:19:18.19834Z","iopub.status.idle":"2022-05-21T06:19:20.753263Z","shell.execute_reply":"2022-05-21T06:19:20.752598Z","shell.execute_reply.started":"2022-05-21T06:19:18.198987Z"},"trusted":true},"outputs":[],"source":["# Let's check our predcitions against some test images\n","plt.figure(figsize=(4,4))\n","for val, i in enumerate(test_imgs[:10]):\n","    try:\n","        img = imageio.imread(i)\n","        imgplot = plt.imshow(img)\n","        plt.title(os.path.basename(i) + ' - Prediction: ' +  f\"{'Autistic' if predictions[val] == 1 else 'Non-Autistic'}\")\n","        plt.show()\n","    except:\n","        val += 1\n"]},{"cell_type":"markdown","metadata":{},"source":["Our model has performed reasonably well for a small training data, we could still improvise the model for greater accuracy"]},{"cell_type":"markdown","metadata":{},"source":["***"]},{"cell_type":"markdown","metadata":{},"source":["## 10. Improvisations"]},{"cell_type":"markdown","metadata":{},"source":["- Providing the model with a large dataset for training can help the model to generalise on new data \n","- Instead of using the small validation dataset (100 images), we can perform Cross Validation on the entire data to prevent overfitting\n","- We can perform fine tuning by training some of the top layers of pre-trained VGG16 model to customise the feature extraction"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":4}
